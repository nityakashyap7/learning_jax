{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b2b665",
   "metadata": {},
   "source": [
    "# Learning Flax\n",
    "tutorial: https://flax-linen.readthedocs.io/en/latest/quick_start.html\n",
    "\n",
    "this tutorial uses Jax + Flax + Optax to build and train a simple CNN on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3787f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # Use only the 3rd GPU \n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform' # makes JAX allocate exactly what is needed on demand, and deallocate memory that is no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7471ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "train_split = 0.8\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "eval_iters = 200 # during eval sample 200 batches from training and test each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bb04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_map\n",
    "from torch.utils.data import DataLoader, default_collate, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from einops import rearrange\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    \"\"\"\n",
    "    Collate function specifies how to combine a list of data samples into a batch. default_collate creates pytorch tensors, then tree_map converts them into numpy arrays\n",
    "    \"\"\"\n",
    "    return tree_map(np.asarray, default_collate(batch))\n",
    "\n",
    "def reshape_and_cast(pic):\n",
    "    \"\"\" convert PIL image to numpy array with shape (28, 28, 1)\"\"\"\n",
    "    return rearrange((np.array(pic, dtype=jnp.float32) / 255.0),  'width height -> width height 1') # use einops to add channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9becdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our dataset using torch datasets\n",
    "mnist_dataset = MNIST('/tmp/mnist/', download=True, transform=reshape_and_cast)\n",
    "\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_split, 1-train_split])\n",
    "\n",
    "# # create pytorch data loaders with custom collate function, one per split\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=numpy_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c341546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8009b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    ''' a simple CNN module'''\n",
    "\n",
    "    @nn.compact # allows u to bypass having to write a setup method (analogous to __init__)\n",
    "    def __call__(self,  x): # __call__() is jax's version of pytorch's forward()\n",
    "        x = nn.Conv(features=32, kernel_size=(3,3))(x) # features = number of output channels\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3,3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "        #x = x.reshape((x.shape[0], -1)) # flatten before fc layer; reshape takes a tuple specifying the new dims \n",
    "        # using einops (better readability):\n",
    "        x = rearrange(x, \"batch width height channels -> batch (width height channels)\") # () indicates flatten these dims\n",
    "        x = nn.Dense(features=256)(x) # features = output dims \n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0482df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 05:28:31.713305: W external/xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.8 which is older than the PTX compiler version 12.9.86. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                  CNN Summary                                   \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mflops\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mvjp_flops\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams    \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
      "│         │ CNN    │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[1,… │ 0     │ 0         │            │\n",
      "├─────────┼────────┼────────────┼─────────────┼───────┼───────────┼────────────┤\n",
      "│ Conv_0  │ Conv   │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[1,… │ 0     │ 0         │ bias:      │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[3… │\n",
      "│         │        │            │             │       │           │ kernel:    │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[3… │\n",
      "│         │        │            │             │       │           │            │\n",
      "│         │        │            │             │       │           │ \u001b[1m320 \u001b[0m\u001b[1;2m(1.3 \u001b[0m  │\n",
      "│         │        │            │             │       │           │ \u001b[1;2mKB)\u001b[0m        │\n",
      "├─────────┼────────┼────────────┼─────────────┼───────┼───────────┼────────────┤\n",
      "│ Conv_1  │ Conv   │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[1,… │ 0     │ 0         │ bias:      │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[6… │\n",
      "│         │        │            │             │       │           │ kernel:    │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[3… │\n",
      "│         │        │            │             │       │           │            │\n",
      "│         │        │            │             │       │           │ \u001b[1m18,496 \u001b[0m    │\n",
      "│         │        │            │             │       │           │ \u001b[1;2m(74.0 KB)\u001b[0m  │\n",
      "├─────────┼────────┼────────────┼─────────────┼───────┼───────────┼────────────┤\n",
      "│ Dense_0 │ Dense  │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[1,… │ 0     │ 0         │ bias:      │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[2… │\n",
      "│         │        │            │             │       │           │ kernel:    │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[3… │\n",
      "│         │        │            │             │       │           │            │\n",
      "│         │        │            │             │       │           │ \u001b[1m803,072 \u001b[0m   │\n",
      "│         │        │            │             │       │           │ \u001b[1;2m(3.2 MB)\u001b[0m   │\n",
      "├─────────┼────────┼────────────┼─────────────┼───────┼───────────┼────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[1,… │ 0     │ 0         │ bias:      │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[1… │\n",
      "│         │        │            │             │       │           │ kernel:    │\n",
      "│         │        │            │             │       │           │ \u001b[2mfloat32\u001b[0m[2… │\n",
      "│         │        │            │             │       │           │            │\n",
      "│         │        │            │             │       │           │ \u001b[1m2,570 \u001b[0m     │\n",
      "│         │        │            │             │       │           │ \u001b[1;2m(10.3 KB)\u001b[0m  │\n",
      "├─────────┼────────┼────────────┼─────────────┼───────┼───────────┼────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m    Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m824,458   \u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m         \u001b[0m│\u001b[1m        \u001b[0m│\u001b[1m            \u001b[0m│\u001b[1m             \u001b[0m│\u001b[1m       \u001b[0m│\u001b[1m           \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2m(3.3 MB)\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴────────────┴─────────────┴───────┴───────────┴────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                       Total Parameters: 824,458 \u001b[0m\u001b[1;2m(3.3 MB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn.tabulate(random.key(0), jnp.ones((1, 28, 28, 1)), compute_flops=True, compute_vjp_flops=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b77e58",
   "metadata": {},
   "source": [
    "tabulate() runs a forward pass to discover the model's structure. Some models may use randomness (such as with dropout) so flax needs a random key to execute those layers.\n",
    "\n",
    "FLOPs = the number of floating-point arithmetic operations (additions, multiplications, etc.) required for a forward pass through the model.\n",
    "\n",
    "VJP FLOPs = the number of floating-point operations required to compute gradients during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71bfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state # useful dataclass to keep train state\n",
    "from flax import struct # flax dataclass\n",
    "import optax # common loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89309a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnityakas\u001b[0m (\u001b[33mnityakas-usc\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nityakas/learning_jax/wandb/run-20260108_052842-wu1l2n3m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST/runs/wu1l2n3m' target=\"_blank\">wild-microwave-15</a></strong> to <a href='https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST' target=\"_blank\">https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST/runs/wu1l2n3m' target=\"_blank\">https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST/runs/wu1l2n3m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nityakas-usc/learning-flax-by-testing-CNN-on-MNIST/runs/wu1l2n3m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f057c51b1a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='learning-flax-by-testing-CNN-on-MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72566106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "    \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "    params = module.init(rng, jnp.ones([1, 28, 28, 1]))['params'] # initialize parameters by passing a template image\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=module.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca3a19",
   "metadata": {},
   "source": [
    "Pytorch vs Flax: \n",
    "in pytorch the model parameters live inside the model class. in flax this is not the case, which enables its optimizations. Without this design, jax.jit(), jax.grad() and jax.vmap() won't work. \n",
    "\n",
    "They make u call apply() so u remember to explicitly pass in the parameters to the model, but under the hood that's just executing model.__call__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed52cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit, value_and_grad\n",
    "\n",
    "def loss_fn(params, state, batch):\n",
    "  logits = state.apply_fn({'params': params}, batch['image'])\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "    logits=logits, labels=batch['label']).mean()\n",
    "  return loss, logits\n",
    "\n",
    "def calculate_accuracy(logits, batch):\n",
    "  preds = jnp.argmax(logits, axis= -1)\n",
    "  accuracy = jnp.mean(preds == batch['label'])\n",
    "  return accuracy\n",
    "\n",
    "@jit\n",
    "def eval(state, batch):\n",
    "  loss, logits = loss_fn(state.params, state, batch)\n",
    "  accuracy = calculate_accuracy(logits, batch)\n",
    "  return loss, accuracy\n",
    "  \n",
    "\n",
    "@jit # apply to whole function\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  #grad_fn = jax.grad(loss_fn, argnums=0) # if u only want grad\n",
    "  func = value_and_grad(loss_fn, argnums=0, has_aux=True)\n",
    "  (loss, logits), grads = func(state.params, state, batch)\n",
    "  accuracy = calculate_accuracy(logits, batch)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71d1be",
   "metadata": {},
   "source": [
    "why does loss_fn need to take in params as an argument?\n",
    "\n",
    "Because when jax.grad() needs to know which params to take the grad of loss_fn wrt to. It expects those params to be the first argument of loss(fn). use `argnums` (default = 0) to tell which positional args to differentiate wrt to (can be more than one)\n",
    "\n",
    "Which functions need the jax.jit decorator?\n",
    "The typical pattern is:\n",
    "- Apply @jax.jit to the top-level functions that orchestrate computations (train_step, eval_step, etc.)  \n",
    "- Keep helper functions like loss_fn or compute_loss as regular Python functions  \n",
    "- JAX will automatically optimize everything when it compiles the outer JITted function  \n",
    "\n",
    "what if i wanna return logits and loss in loss_fn, not just loss?\n",
    "jax.value_and_grad and jax.grad allow u to specify `has_aux` for this.  \n",
    "- has_aux=True tells JAX that loss_fn returns (value, auxiliary_data)\n",
    "JAX only differentiates w.r.t. the first return value (loss).  \n",
    "- The second return value (logits) is passed through unchanged as \"auxiliary\" data.  \n",
    "- You get back ((loss, logits), grads) - note the nested tuple structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b1ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_rng = random.key(0)\n",
    "\n",
    "state = create_train_state(cnn, init_rng, learning_rate=learning_rate, momentum=momentum)\n",
    "del init_rng  # Must not be used anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df198f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for img_batch, label_batch in train_loader:\n",
    " \n",
    "        batch = {'image': img_batch, 'label': label_batch}\n",
    "        state = train_step(state, batch) # forward pass, backward pass, logs metrics to wandb\n",
    "\n",
    "    # evaluation on both training and val data after each epoch\n",
    "    t_losses = []\n",
    "    t_accs = []\n",
    "    v_losses = []\n",
    "    v_accs = []\n",
    "    for _ in range(eval_iters):\n",
    "        img_batch, label_batch = next(iter(train_loader)) \n",
    "        train_batch = {'image': img_batch, 'label': label_batch}\n",
    "        loss, accuracy = eval(state, train_batch)\n",
    "        t_losses.append(loss)\n",
    "        t_accs.append(accuracy)\n",
    "        \n",
    "        img_batch, label_batch = next(iter(val_loader)) \n",
    "        val_batch = {'image': img_batch, 'label': label_batch}\n",
    "        loss, accuracy = eval(state, val_batch)\n",
    "        v_losses.append(loss)\n",
    "        v_accs.append(accuracy)\n",
    "\n",
    "    t_losses = np.array(t_losses)\n",
    "    v_losses = np.array(v_losses)\n",
    "    t_accs = np.array(t_accs)\n",
    "    v_accs = np.array(v_accs)\n",
    "\n",
    "    wandb.log({'train loss': np.mean(t_losses), 'train acc': np.mean(t_accs), 'val loss': np.mean(v_losses), 'val acc': np.mean(v_accs)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084fdef2",
   "metadata": {},
   "source": [
    "since we're using `optax.softmax_cross_entropy_with_integer_labels()` in `loss_fn()`, we dont need to convert the labels to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "159263cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (32,)\n",
      "Predictions: [1 8 8 3 2 0 3 0 2 7 2 1 6 3 1 0 0 6 1 2 3 4 1 9 2 1 8 7 2 9 0 1]\n",
      "\n",
      "Actual labels: [1 5 8 3 2 0 3 0 2 7 2 1 6 3 1 0 0 6 1 2 3 6 1 9 2 1 8 7 2 9 0 1]\n"
     ]
    }
   ],
   "source": [
    "def classify(state, batch):\n",
    "    logits = state.apply_fn({'params': state.params}, batch['image'])\n",
    "    preds = jnp.argmax(logits, axis=-1)\n",
    "    return preds\n",
    "\n",
    "\n",
    "img_batch, label_batch = next(iter(val_loader))\n",
    "val_batch = {'image': img_batch, 'label': label_batch}\n",
    "\n",
    "preds = classify(state, val_batch)\n",
    "print(\"Predictions shape:\", preds.shape)\n",
    "print(\"Predictions:\", preds)\n",
    "print(\"\\nActual labels:\", val_batch['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
